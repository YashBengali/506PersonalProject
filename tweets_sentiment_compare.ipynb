{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1300 entries, 0 to 1299\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          1300 non-null   int64 \n",
      " 1   created_at  1300 non-null   object\n",
      " 2   text        1300 non-null   object\n",
      " 3   Score       1300 non-null   int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 50.8+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_stock_tweets_labled():\n",
    "    df = pd.read_csv('tweets_labelled.csv', sep=';')\n",
    "    df.dropna(inplace=True)\n",
    "    df['sentiment'] = df['sentiment'].apply(lambda x:1 if x == 'positive' else 0)\n",
    "    df = df.rename(columns={\"sentiment\": \"Score\"})\n",
    "    return df\n",
    "\n",
    "df = read_stock_tweets_labled()\n",
    "df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stemmed\n",
      "here\n",
      "this done\n",
      "shape\n",
      "(1300, 60)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1300 entries, 0 to 1299\n",
      "Data columns (total 64 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   id          1300 non-null   int64  \n",
      " 1   created_at  1300 non-null   object \n",
      " 2   text        1300 non-null   object \n",
      " 3   Score       1300 non-null   int64  \n",
      " 4   svd0        1300 non-null   float64\n",
      " 5   svd1        1300 non-null   float64\n",
      " 6   svd2        1300 non-null   float64\n",
      " 7   svd3        1300 non-null   float64\n",
      " 8   svd4        1300 non-null   float64\n",
      " 9   svd5        1300 non-null   float64\n",
      " 10  svd6        1300 non-null   float64\n",
      " 11  svd7        1300 non-null   float64\n",
      " 12  svd8        1300 non-null   float64\n",
      " 13  svd9        1300 non-null   float64\n",
      " 14  svd10       1300 non-null   float64\n",
      " 15  svd11       1300 non-null   float64\n",
      " 16  svd12       1300 non-null   float64\n",
      " 17  svd13       1300 non-null   float64\n",
      " 18  svd14       1300 non-null   float64\n",
      " 19  svd15       1300 non-null   float64\n",
      " 20  svd16       1300 non-null   float64\n",
      " 21  svd17       1300 non-null   float64\n",
      " 22  svd18       1300 non-null   float64\n",
      " 23  svd19       1300 non-null   float64\n",
      " 24  svd20       1300 non-null   float64\n",
      " 25  svd21       1300 non-null   float64\n",
      " 26  svd22       1300 non-null   float64\n",
      " 27  svd23       1300 non-null   float64\n",
      " 28  svd24       1300 non-null   float64\n",
      " 29  svd25       1300 non-null   float64\n",
      " 30  svd26       1300 non-null   float64\n",
      " 31  svd27       1300 non-null   float64\n",
      " 32  svd28       1300 non-null   float64\n",
      " 33  svd29       1300 non-null   float64\n",
      " 34  svd30       1300 non-null   float64\n",
      " 35  svd31       1300 non-null   float64\n",
      " 36  svd32       1300 non-null   float64\n",
      " 37  svd33       1300 non-null   float64\n",
      " 38  svd34       1300 non-null   float64\n",
      " 39  svd35       1300 non-null   float64\n",
      " 40  svd36       1300 non-null   float64\n",
      " 41  svd37       1300 non-null   float64\n",
      " 42  svd38       1300 non-null   float64\n",
      " 43  svd39       1300 non-null   float64\n",
      " 44  svd40       1300 non-null   float64\n",
      " 45  svd41       1300 non-null   float64\n",
      " 46  svd42       1300 non-null   float64\n",
      " 47  svd43       1300 non-null   float64\n",
      " 48  svd44       1300 non-null   float64\n",
      " 49  svd45       1300 non-null   float64\n",
      " 50  svd46       1300 non-null   float64\n",
      " 51  svd47       1300 non-null   float64\n",
      " 52  svd48       1300 non-null   float64\n",
      " 53  svd49       1300 non-null   float64\n",
      " 54  svd50       1300 non-null   float64\n",
      " 55  svd51       1300 non-null   float64\n",
      " 56  svd52       1300 non-null   float64\n",
      " 57  svd53       1300 non-null   float64\n",
      " 58  svd54       1300 non-null   float64\n",
      " 59  svd55       1300 non-null   float64\n",
      " 60  svd56       1300 non-null   float64\n",
      " 61  svd57       1300 non-null   float64\n",
      " 62  svd58       1300 non-null   float64\n",
      " 63  svd59       1300 non-null   float64\n",
      "dtypes: float64(60), int64(2), object(2)\n",
      "memory usage: 660.2+ KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import numpy as np\n",
    "\n",
    "def process(df):\n",
    "    #trying tfidf \n",
    "    stemmed_data = [\" \".join(SnowballStemmer(\"english\", ignore_stopwords=True).stem(word)  \n",
    "         for sent in sent_tokenize(message)\n",
    "        for word in word_tokenize(sent))\n",
    "        for message in  df['text']]\n",
    "    print('stemmed')\n",
    "    vectorizer = TfidfVectorizer(stop_words = 'english', min_df = 4, max_df = 0.8)\n",
    "    dtm = vectorizer.fit_transform(stemmed_data)\n",
    "    num_features = 60\n",
    "    svd = TruncatedSVD(num_features)\n",
    "    print('here')\n",
    "    normalizer = Normalizer(copy=False)\n",
    "    print('this done')\n",
    "    lsa = make_pipeline(svd, normalizer)\n",
    "    dtm = lsa.fit_transform(dtm)\n",
    "    print('shape')\n",
    "    print(np.shape(dtm))\n",
    "    dtm = np.transpose(dtm)\n",
    "    columns = ['svd' + str(i) for i in range(num_features)]\n",
    "    # svd = pd.DataFrame(dtm, columns=columns)\n",
    "    # svd.fillna(0)\n",
    "    # labels= ['SV'+str(i) for i num_features]\n",
    "    for i in range(num_features):\n",
    "        name = 'svd' + str(i)\n",
    "        # print(np.shape(dtm[:][i]))\n",
    "        df[name] = dtm[i]\n",
    "        df[name] = df[name].fillna('')\n",
    "\n",
    "    return df\n",
    "\n",
    "process(df)\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing the infos\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 975 entries, 1268 to 684\n",
      "Data columns (total 60 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   svd0    975 non-null    float64\n",
      " 1   svd1    975 non-null    float64\n",
      " 2   svd2    975 non-null    float64\n",
      " 3   svd3    975 non-null    float64\n",
      " 4   svd4    975 non-null    float64\n",
      " 5   svd5    975 non-null    float64\n",
      " 6   svd6    975 non-null    float64\n",
      " 7   svd7    975 non-null    float64\n",
      " 8   svd8    975 non-null    float64\n",
      " 9   svd9    975 non-null    float64\n",
      " 10  svd10   975 non-null    float64\n",
      " 11  svd11   975 non-null    float64\n",
      " 12  svd12   975 non-null    float64\n",
      " 13  svd13   975 non-null    float64\n",
      " 14  svd14   975 non-null    float64\n",
      " 15  svd15   975 non-null    float64\n",
      " 16  svd16   975 non-null    float64\n",
      " 17  svd17   975 non-null    float64\n",
      " 18  svd18   975 non-null    float64\n",
      " 19  svd19   975 non-null    float64\n",
      " 20  svd20   975 non-null    float64\n",
      " 21  svd21   975 non-null    float64\n",
      " 22  svd22   975 non-null    float64\n",
      " 23  svd23   975 non-null    float64\n",
      " 24  svd24   975 non-null    float64\n",
      " 25  svd25   975 non-null    float64\n",
      " 26  svd26   975 non-null    float64\n",
      " 27  svd27   975 non-null    float64\n",
      " 28  svd28   975 non-null    float64\n",
      " 29  svd29   975 non-null    float64\n",
      " 30  svd30   975 non-null    float64\n",
      " 31  svd31   975 non-null    float64\n",
      " 32  svd32   975 non-null    float64\n",
      " 33  svd33   975 non-null    float64\n",
      " 34  svd34   975 non-null    float64\n",
      " 35  svd35   975 non-null    float64\n",
      " 36  svd36   975 non-null    float64\n",
      " 37  svd37   975 non-null    float64\n",
      " 38  svd38   975 non-null    float64\n",
      " 39  svd39   975 non-null    float64\n",
      " 40  svd40   975 non-null    float64\n",
      " 41  svd41   975 non-null    float64\n",
      " 42  svd42   975 non-null    float64\n",
      " 43  svd43   975 non-null    float64\n",
      " 44  svd44   975 non-null    float64\n",
      " 45  svd45   975 non-null    float64\n",
      " 46  svd46   975 non-null    float64\n",
      " 47  svd47   975 non-null    float64\n",
      " 48  svd48   975 non-null    float64\n",
      " 49  svd49   975 non-null    float64\n",
      " 50  svd50   975 non-null    float64\n",
      " 51  svd51   975 non-null    float64\n",
      " 52  svd52   975 non-null    float64\n",
      " 53  svd53   975 non-null    float64\n",
      " 54  svd54   975 non-null    float64\n",
      " 55  svd55   975 non-null    float64\n",
      " 56  svd56   975 non-null    float64\n",
      " 57  svd57   975 non-null    float64\n",
      " 58  svd58   975 non-null    float64\n",
      " 59  svd59   975 non-null    float64\n",
      "dtypes: float64(60)\n",
      "memory usage: 464.6 KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 325 entries, 579 to 82\n",
      "Data columns (total 60 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   svd0    325 non-null    float64\n",
      " 1   svd1    325 non-null    float64\n",
      " 2   svd2    325 non-null    float64\n",
      " 3   svd3    325 non-null    float64\n",
      " 4   svd4    325 non-null    float64\n",
      " 5   svd5    325 non-null    float64\n",
      " 6   svd6    325 non-null    float64\n",
      " 7   svd7    325 non-null    float64\n",
      " 8   svd8    325 non-null    float64\n",
      " 9   svd9    325 non-null    float64\n",
      " 10  svd10   325 non-null    float64\n",
      " 11  svd11   325 non-null    float64\n",
      " 12  svd12   325 non-null    float64\n",
      " 13  svd13   325 non-null    float64\n",
      " 14  svd14   325 non-null    float64\n",
      " 15  svd15   325 non-null    float64\n",
      " 16  svd16   325 non-null    float64\n",
      " 17  svd17   325 non-null    float64\n",
      " 18  svd18   325 non-null    float64\n",
      " 19  svd19   325 non-null    float64\n",
      " 20  svd20   325 non-null    float64\n",
      " 21  svd21   325 non-null    float64\n",
      " 22  svd22   325 non-null    float64\n",
      " 23  svd23   325 non-null    float64\n",
      " 24  svd24   325 non-null    float64\n",
      " 25  svd25   325 non-null    float64\n",
      " 26  svd26   325 non-null    float64\n",
      " 27  svd27   325 non-null    float64\n",
      " 28  svd28   325 non-null    float64\n",
      " 29  svd29   325 non-null    float64\n",
      " 30  svd30   325 non-null    float64\n",
      " 31  svd31   325 non-null    float64\n",
      " 32  svd32   325 non-null    float64\n",
      " 33  svd33   325 non-null    float64\n",
      " 34  svd34   325 non-null    float64\n",
      " 35  svd35   325 non-null    float64\n",
      " 36  svd36   325 non-null    float64\n",
      " 37  svd37   325 non-null    float64\n",
      " 38  svd38   325 non-null    float64\n",
      " 39  svd39   325 non-null    float64\n",
      " 40  svd40   325 non-null    float64\n",
      " 41  svd41   325 non-null    float64\n",
      " 42  svd42   325 non-null    float64\n",
      " 43  svd43   325 non-null    float64\n",
      " 44  svd44   325 non-null    float64\n",
      " 45  svd45   325 non-null    float64\n",
      " 46  svd46   325 non-null    float64\n",
      " 47  svd47   325 non-null    float64\n",
      " 48  svd48   325 non-null    float64\n",
      " 49  svd49   325 non-null    float64\n",
      " 50  svd50   325 non-null    float64\n",
      " 51  svd51   325 non-null    float64\n",
      " 52  svd52   325 non-null    float64\n",
      " 53  svd53   325 non-null    float64\n",
      " 54  svd54   325 non-null    float64\n",
      " 55  svd55   325 non-null    float64\n",
      " 56  svd56   325 non-null    float64\n",
      " 57  svd57   325 non-null    float64\n",
      " 58  svd58   325 non-null    float64\n",
      " 59  svd59   325 non-null    float64\n",
      "dtypes: float64(60)\n",
      "memory usage: 154.9 KB\n",
      "None\n",
      "(975, 60) (975,)\n",
      "(325, 60) (325,)\n",
      "got the predictions\n",
      "325\n",
      "325 325\n",
      "RMSE on testing set =  0.243792821884065\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix\n",
    "from sklearn import utils\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Load files into DataFrames\n",
    "\n",
    "\n",
    "def get_model(df):\n",
    "\n",
    "    X_train = df\n",
    "\n",
    "    # X_train = utils.shuffle(X_train, random_state=1)\n",
    "\n",
    "    # Split training set into training and testing set\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "            X_train.drop(['Score'], axis=1),\n",
    "            X_train['Score'],\n",
    "            test_size=1/4.0,\n",
    "            random_state=0\n",
    "        )\n",
    "\n",
    "    X_train_processed = X_train.drop(columns=['id', 'created_at', 'text'])\n",
    "    X_test_processed = X_test.drop(columns=['id', 'created_at', 'text'])\n",
    "    # X_submission_processed = X_submission.drop(columns=['Id', 'Time', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'ProductId', 'UserId', 'Text', 'Summary', 'Score'])\n",
    "\n",
    "    # print(Y_train.head)\n",
    "    # Y_train = Y_train.fillna(4) #shouldn't need to do this\n",
    "    # print(Y_train.isnull().values.any())\n",
    "\n",
    "    # print(Y_test.head)\n",
    "    # print(Y_test.isnull().values.any())\n",
    "    # Y_test = Y_test.fillna(4) #shouldn't need to do this\n",
    "\n",
    "    print('printing the infos')\n",
    "    print(X_train_processed.info())\n",
    "    print(X_test_processed.info())\n",
    "    # print(X_train_processed.isnull().values.any())\n",
    "\n",
    "\n",
    "    print((X_train_processed.shape), Y_train.shape)\n",
    "    print((X_test_processed.shape), Y_test.shape)\n",
    "\n",
    "\n",
    "    # print(X_train[X_train.columns[0]].head(10))\n",
    "    # subX_train = (X_train['good_cnt']) / (X_train['good_cnt'] + X_train['bad_cnt'] + X_train['okay_cnt'])\n",
    "    # # subX_test = X_test[X_test['Score']]\n",
    "    # plt.scatter(subX_train, Y_train, c=\"slategray\", alpha=0.4, linewidths=0.1)\n",
    "    # # plt.scatter(subX_test, y_CA_H_test, c=\"seagreen\", alpha=0.2, linewidths=0.3)\n",
    "    # plt.xlabel('ProductScore')\n",
    "    # plt.ylabel('Actual Score')\n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "    # Predict the score using the model\n",
    "\n",
    "    # print(X_train['good_cntSummary'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # model = sm.OLS(Y_train, X_train_processed)\n",
    "    # results = model.fit()\n",
    "    # print(results.summary())\n",
    "    # Y_test_predictions = model.predict(np.transpose(X_test_processed))\n",
    "\n",
    "    model = XGBRegressor()\n",
    "    model.fit(X_train_processed, Y_train)\n",
    "    Y_test_predictions = model.predict(X_test_processed)\n",
    "\n",
    "\n",
    "    # print(Y_test_predictions.isnull().values.any())\n",
    "    # print(Y_test.isnull().values.any())\n",
    "    print('got the predictions')\n",
    "    print(len(Y_test_predictions))\n",
    "    # Y_test_predictions = Y_test_predictions.round()\n",
    "    # Y_test_predictions = [min(5, max(1, x)) for x in Y_test_predictions] \n",
    "\n",
    "    print(str(len(Y_test)) + ' ' + str(len(Y_test_predictions)))\n",
    "\n",
    "    print(\"RMSE on testing set = \", mean_squared_error(Y_test, Y_test_predictions))\n",
    "\n",
    "    # prediction['Score'] = ret\n",
    "\n",
    "    # submission = prediction[['Id', 'Score']]\n",
    "    # print(Y_test_predictions.head())\n",
    "    # Y_test_predictions.to_csv(\"./data/y_test_submission.csv\", index=False)\n",
    "\n",
    "    # Plot a confusion matrix\n",
    "    # cm = confusion_matrix(Y_test, Y_test_predictions, normalize='true')\n",
    "    # sns.heatmap(cm, annot=True)\n",
    "    # plt.title('Confusion matrix of the classifier')\n",
    "    # plt.xlabel('Predicted')\n",
    "    # plt.ylabel('True')\n",
    "    # plt.show()\n",
    "\n",
    "    return model\n",
    "\n",
    "model = get_model(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stemmed\n",
      "here\n",
      "this done\n",
      "shape\n",
      "(79565, 60)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79565 entries, 0 to 79564\n",
      "Data columns (total 64 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   date       79565 non-null  object \n",
      " 1   followers  79563 non-null  object \n",
      " 2   likes      79563 non-null  object \n",
      " 3   text       79565 non-null  object \n",
      " 4   svd0       79565 non-null  float64\n",
      " 5   svd1       79565 non-null  float64\n",
      " 6   svd2       79565 non-null  float64\n",
      " 7   svd3       79565 non-null  float64\n",
      " 8   svd4       79565 non-null  float64\n",
      " 9   svd5       79565 non-null  float64\n",
      " 10  svd6       79565 non-null  float64\n",
      " 11  svd7       79565 non-null  float64\n",
      " 12  svd8       79565 non-null  float64\n",
      " 13  svd9       79565 non-null  float64\n",
      " 14  svd10      79565 non-null  float64\n",
      " 15  svd11      79565 non-null  float64\n",
      " 16  svd12      79565 non-null  float64\n",
      " 17  svd13      79565 non-null  float64\n",
      " 18  svd14      79565 non-null  float64\n",
      " 19  svd15      79565 non-null  float64\n",
      " 20  svd16      79565 non-null  float64\n",
      " 21  svd17      79565 non-null  float64\n",
      " 22  svd18      79565 non-null  float64\n",
      " 23  svd19      79565 non-null  float64\n",
      " 24  svd20      79565 non-null  float64\n",
      " 25  svd21      79565 non-null  float64\n",
      " 26  svd22      79565 non-null  float64\n",
      " 27  svd23      79565 non-null  float64\n",
      " 28  svd24      79565 non-null  float64\n",
      " 29  svd25      79565 non-null  float64\n",
      " 30  svd26      79565 non-null  float64\n",
      " 31  svd27      79565 non-null  float64\n",
      " 32  svd28      79565 non-null  float64\n",
      " 33  svd29      79565 non-null  float64\n",
      " 34  svd30      79565 non-null  float64\n",
      " 35  svd31      79565 non-null  float64\n",
      " 36  svd32      79565 non-null  float64\n",
      " 37  svd33      79565 non-null  float64\n",
      " 38  svd34      79565 non-null  float64\n",
      " 39  svd35      79565 non-null  float64\n",
      " 40  svd36      79565 non-null  float64\n",
      " 41  svd37      79565 non-null  float64\n",
      " 42  svd38      79565 non-null  float64\n",
      " 43  svd39      79565 non-null  float64\n",
      " 44  svd40      79565 non-null  float64\n",
      " 45  svd41      79565 non-null  float64\n",
      " 46  svd42      79565 non-null  float64\n",
      " 47  svd43      79565 non-null  float64\n",
      " 48  svd44      79565 non-null  float64\n",
      " 49  svd45      79565 non-null  float64\n",
      " 50  svd46      79565 non-null  float64\n",
      " 51  svd47      79565 non-null  float64\n",
      " 52  svd48      79565 non-null  float64\n",
      " 53  svd49      79565 non-null  float64\n",
      " 54  svd50      79565 non-null  float64\n",
      " 55  svd51      79565 non-null  float64\n",
      " 56  svd52      79565 non-null  float64\n",
      " 57  svd53      79565 non-null  float64\n",
      " 58  svd54      79565 non-null  float64\n",
      " 59  svd55      79565 non-null  float64\n",
      " 60  svd56      79565 non-null  float64\n",
      " 61  svd57      79565 non-null  float64\n",
      " 62  svd58      79565 non-null  float64\n",
      " 63  svd59      79565 non-null  float64\n",
      "dtypes: float64(60), object(4)\n",
      "memory usage: 38.9+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets = pd.read_csv(\"tweets.csv\")\n",
    "\n",
    "tweets = tweets.rename(columns={'tweet': 'text'})\n",
    "# tweets.drop(columns=['writer', 'comment_num','retweet_num','like_num'])\n",
    "\n",
    "tweets['text'] = tweets['text'].apply(lambda x : '' if not (type(x) == type('a')) else x)\n",
    "\n",
    "tweets = process(tweets)\n",
    "\n",
    "tweets.to_csv(\"recent_tweets_processed.csv\", index=False)\n",
    "\n",
    "tweets.info()   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 79563 entries, 0 to 79564\n",
      "Data columns (total 65 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   date       79563 non-null  object \n",
      " 1   followers  79563 non-null  object \n",
      " 2   likes      79563 non-null  object \n",
      " 3   text       79563 non-null  object \n",
      " 4   svd0       79563 non-null  float64\n",
      " 5   svd1       79563 non-null  float64\n",
      " 6   svd2       79563 non-null  float64\n",
      " 7   svd3       79563 non-null  float64\n",
      " 8   svd4       79563 non-null  float64\n",
      " 9   svd5       79563 non-null  float64\n",
      " 10  svd6       79563 non-null  float64\n",
      " 11  svd7       79563 non-null  float64\n",
      " 12  svd8       79563 non-null  float64\n",
      " 13  svd9       79563 non-null  float64\n",
      " 14  svd10      79563 non-null  float64\n",
      " 15  svd11      79563 non-null  float64\n",
      " 16  svd12      79563 non-null  float64\n",
      " 17  svd13      79563 non-null  float64\n",
      " 18  svd14      79563 non-null  float64\n",
      " 19  svd15      79563 non-null  float64\n",
      " 20  svd16      79563 non-null  float64\n",
      " 21  svd17      79563 non-null  float64\n",
      " 22  svd18      79563 non-null  float64\n",
      " 23  svd19      79563 non-null  float64\n",
      " 24  svd20      79563 non-null  float64\n",
      " 25  svd21      79563 non-null  float64\n",
      " 26  svd22      79563 non-null  float64\n",
      " 27  svd23      79563 non-null  float64\n",
      " 28  svd24      79563 non-null  float64\n",
      " 29  svd25      79563 non-null  float64\n",
      " 30  svd26      79563 non-null  float64\n",
      " 31  svd27      79563 non-null  float64\n",
      " 32  svd28      79563 non-null  float64\n",
      " 33  svd29      79563 non-null  float64\n",
      " 34  svd30      79563 non-null  float64\n",
      " 35  svd31      79563 non-null  float64\n",
      " 36  svd32      79563 non-null  float64\n",
      " 37  svd33      79563 non-null  float64\n",
      " 38  svd34      79563 non-null  float64\n",
      " 39  svd35      79563 non-null  float64\n",
      " 40  svd36      79563 non-null  float64\n",
      " 41  svd37      79563 non-null  float64\n",
      " 42  svd38      79563 non-null  float64\n",
      " 43  svd39      79563 non-null  float64\n",
      " 44  svd40      79563 non-null  float64\n",
      " 45  svd41      79563 non-null  float64\n",
      " 46  svd42      79563 non-null  float64\n",
      " 47  svd43      79563 non-null  float64\n",
      " 48  svd44      79563 non-null  float64\n",
      " 49  svd45      79563 non-null  float64\n",
      " 50  svd46      79563 non-null  float64\n",
      " 51  svd47      79563 non-null  float64\n",
      " 52  svd48      79563 non-null  float64\n",
      " 53  svd49      79563 non-null  float64\n",
      " 54  svd50      79563 non-null  float64\n",
      " 55  svd51      79563 non-null  float64\n",
      " 56  svd52      79563 non-null  float64\n",
      " 57  svd53      79563 non-null  float64\n",
      " 58  svd54      79563 non-null  float64\n",
      " 59  svd55      79563 non-null  float64\n",
      " 60  svd56      79563 non-null  float64\n",
      " 61  svd57      79563 non-null  float64\n",
      " 62  svd58      79563 non-null  float64\n",
      " 63  svd59      79563 non-null  float64\n",
      " 64  DATE       79563 non-null  object \n",
      "dtypes: float64(60), object(5)\n",
      "memory usage: 40.1+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 79563 entries, 0 to 79564\n",
      "Data columns (total 66 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   date       79563 non-null  object \n",
      " 1   followers  79563 non-null  object \n",
      " 2   likes      79563 non-null  object \n",
      " 3   text       79563 non-null  object \n",
      " 4   svd0       79563 non-null  float64\n",
      " 5   svd1       79563 non-null  float64\n",
      " 6   svd2       79563 non-null  float64\n",
      " 7   svd3       79563 non-null  float64\n",
      " 8   svd4       79563 non-null  float64\n",
      " 9   svd5       79563 non-null  float64\n",
      " 10  svd6       79563 non-null  float64\n",
      " 11  svd7       79563 non-null  float64\n",
      " 12  svd8       79563 non-null  float64\n",
      " 13  svd9       79563 non-null  float64\n",
      " 14  svd10      79563 non-null  float64\n",
      " 15  svd11      79563 non-null  float64\n",
      " 16  svd12      79563 non-null  float64\n",
      " 17  svd13      79563 non-null  float64\n",
      " 18  svd14      79563 non-null  float64\n",
      " 19  svd15      79563 non-null  float64\n",
      " 20  svd16      79563 non-null  float64\n",
      " 21  svd17      79563 non-null  float64\n",
      " 22  svd18      79563 non-null  float64\n",
      " 23  svd19      79563 non-null  float64\n",
      " 24  svd20      79563 non-null  float64\n",
      " 25  svd21      79563 non-null  float64\n",
      " 26  svd22      79563 non-null  float64\n",
      " 27  svd23      79563 non-null  float64\n",
      " 28  svd24      79563 non-null  float64\n",
      " 29  svd25      79563 non-null  float64\n",
      " 30  svd26      79563 non-null  float64\n",
      " 31  svd27      79563 non-null  float64\n",
      " 32  svd28      79563 non-null  float64\n",
      " 33  svd29      79563 non-null  float64\n",
      " 34  svd30      79563 non-null  float64\n",
      " 35  svd31      79563 non-null  float64\n",
      " 36  svd32      79563 non-null  float64\n",
      " 37  svd33      79563 non-null  float64\n",
      " 38  svd34      79563 non-null  float64\n",
      " 39  svd35      79563 non-null  float64\n",
      " 40  svd36      79563 non-null  float64\n",
      " 41  svd37      79563 non-null  float64\n",
      " 42  svd38      79563 non-null  float64\n",
      " 43  svd39      79563 non-null  float64\n",
      " 44  svd40      79563 non-null  float64\n",
      " 45  svd41      79563 non-null  float64\n",
      " 46  svd42      79563 non-null  float64\n",
      " 47  svd43      79563 non-null  float64\n",
      " 48  svd44      79563 non-null  float64\n",
      " 49  svd45      79563 non-null  float64\n",
      " 50  svd46      79563 non-null  float64\n",
      " 51  svd47      79563 non-null  float64\n",
      " 52  svd48      79563 non-null  float64\n",
      " 53  svd49      79563 non-null  float64\n",
      " 54  svd50      79563 non-null  float64\n",
      " 55  svd51      79563 non-null  float64\n",
      " 56  svd52      79563 non-null  float64\n",
      " 57  svd53      79563 non-null  float64\n",
      " 58  svd54      79563 non-null  float64\n",
      " 59  svd55      79563 non-null  float64\n",
      " 60  svd56      79563 non-null  float64\n",
      " 61  svd57      79563 non-null  float64\n",
      " 62  svd58      79563 non-null  float64\n",
      " 63  svd59      79563 non-null  float64\n",
      " 64  DATE       79563 non-null  object \n",
      " 65  sent       79563 non-null  float32\n",
      "dtypes: float32(1), float64(60), object(5)\n",
      "memory usage: 40.4+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "# tweets = pd.read_csv('tweets_processed.csv')\n",
    "\n",
    "# tweets['date'] = tweets['date'].apply(lambda x : str(datetime.fromtimestamp(x)))\n",
    "\n",
    "print(tweets.info())\n",
    "\n",
    "\n",
    "date = tweets.date.str.split(expand=True)\n",
    "tweets[\"DATE\"] = date[0]\n",
    "tweets.sort_values(by=['DATE'])\n",
    "tweets = tweets[tweets.DATE != 'date']\n",
    "tweets = tweets[tweets.DATE != '=======']\n",
    "\n",
    "\n",
    "tweets_dropped = tweets.drop(columns=['date', 'followers', 'likes', 'text', 'DATE'], inplace=False)\n",
    "#     X_test_processed = X_test.drop(columns=['id', 'created_at', 'text'])\n",
    "predictions = model.predict(tweets_dropped)\n",
    "\n",
    "tweets['sent'] = predictions\n",
    "\n",
    "tweets.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79562 entries, 0 to 79561\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   SCORE      79562 non-null  float64\n",
      " 1   MAGNITUDE  79562 non-null  float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 1.2 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 79563 entries, 0 to 79564\n",
      "Data columns (total 67 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   date       79563 non-null  object \n",
      " 1   followers  79563 non-null  object \n",
      " 2   likes      79563 non-null  object \n",
      " 3   text       79563 non-null  object \n",
      " 4   svd0       79563 non-null  float64\n",
      " 5   svd1       79563 non-null  float64\n",
      " 6   svd2       79563 non-null  float64\n",
      " 7   svd3       79563 non-null  float64\n",
      " 8   svd4       79563 non-null  float64\n",
      " 9   svd5       79563 non-null  float64\n",
      " 10  svd6       79563 non-null  float64\n",
      " 11  svd7       79563 non-null  float64\n",
      " 12  svd8       79563 non-null  float64\n",
      " 13  svd9       79563 non-null  float64\n",
      " 14  svd10      79563 non-null  float64\n",
      " 15  svd11      79563 non-null  float64\n",
      " 16  svd12      79563 non-null  float64\n",
      " 17  svd13      79563 non-null  float64\n",
      " 18  svd14      79563 non-null  float64\n",
      " 19  svd15      79563 non-null  float64\n",
      " 20  svd16      79563 non-null  float64\n",
      " 21  svd17      79563 non-null  float64\n",
      " 22  svd18      79563 non-null  float64\n",
      " 23  svd19      79563 non-null  float64\n",
      " 24  svd20      79563 non-null  float64\n",
      " 25  svd21      79563 non-null  float64\n",
      " 26  svd22      79563 non-null  float64\n",
      " 27  svd23      79563 non-null  float64\n",
      " 28  svd24      79563 non-null  float64\n",
      " 29  svd25      79563 non-null  float64\n",
      " 30  svd26      79563 non-null  float64\n",
      " 31  svd27      79563 non-null  float64\n",
      " 32  svd28      79563 non-null  float64\n",
      " 33  svd29      79563 non-null  float64\n",
      " 34  svd30      79563 non-null  float64\n",
      " 35  svd31      79563 non-null  float64\n",
      " 36  svd32      79563 non-null  float64\n",
      " 37  svd33      79563 non-null  float64\n",
      " 38  svd34      79563 non-null  float64\n",
      " 39  svd35      79563 non-null  float64\n",
      " 40  svd36      79563 non-null  float64\n",
      " 41  svd37      79563 non-null  float64\n",
      " 42  svd38      79563 non-null  float64\n",
      " 43  svd39      79563 non-null  float64\n",
      " 44  svd40      79563 non-null  float64\n",
      " 45  svd41      79563 non-null  float64\n",
      " 46  svd42      79563 non-null  float64\n",
      " 47  svd43      79563 non-null  float64\n",
      " 48  svd44      79563 non-null  float64\n",
      " 49  svd45      79563 non-null  float64\n",
      " 50  svd46      79563 non-null  float64\n",
      " 51  svd47      79563 non-null  float64\n",
      " 52  svd48      79563 non-null  float64\n",
      " 53  svd49      79563 non-null  float64\n",
      " 54  svd50      79563 non-null  float64\n",
      " 55  svd51      79563 non-null  float64\n",
      " 56  svd52      79563 non-null  float64\n",
      " 57  svd53      79563 non-null  float64\n",
      " 58  svd54      79563 non-null  float64\n",
      " 59  svd55      79563 non-null  float64\n",
      " 60  svd56      79563 non-null  float64\n",
      " 61  svd57      79563 non-null  float64\n",
      " 62  svd58      79563 non-null  float64\n",
      " 63  svd59      79563 non-null  float64\n",
      " 64  DATE       79563 non-null  object \n",
      " 65  sent       79563 non-null  float32\n",
      " 66  google     79560 non-null  float64\n",
      "dtypes: float32(1), float64(61), object(5)\n",
      "memory usage: 41.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def read_sent():\n",
    "    df = pd.read_csv('sentiments.csv')\n",
    "    return df\n",
    "\n",
    "sent = read_sent()\n",
    "\n",
    "print(sent.info())\n",
    "\n",
    "tweets['google'] = sent['SCORE']\n",
    "print(tweets.info())\n",
    "\n",
    "print(tweets[\"sent\"].corr(tweets[\"google\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Mean_Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>0.412905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0.102065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>0.257672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>1.224695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>0.594274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>2019-09-18</td>\n",
       "      <td>0.439712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>0.345741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>2019-09-20</td>\n",
       "      <td>0.418222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>2019-09-21</td>\n",
       "      <td>0.342253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>2019-09-22</td>\n",
       "      <td>0.197821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1347 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Mean_Sentiment\n",
       "0     2014-12-31        0.412905\n",
       "1     2015-01-01        0.102065\n",
       "2     2015-01-04        0.257672\n",
       "3     2015-01-05        1.224695\n",
       "4     2015-01-08        0.594274\n",
       "...          ...             ...\n",
       "1342  2019-09-18        0.439712\n",
       "1343  2019-09-19        0.345741\n",
       "1344  2019-09-20        0.418222\n",
       "1345  2019-09-21        0.342253\n",
       "1346  2019-09-22        0.197821\n",
       "\n",
       "[1347 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data = pd.read_csv(\"AAPL.csv\")\n",
    "\n",
    "# limit tweets to tweets with over 10 likes\n",
    "\n",
    "tweets = tweets[tweets.apply(lambda x : int(x['like_num']) > 20 and int(x['comment_num']) > 5, axis=1)]\n",
    "\n",
    "\n",
    "grouped_df = tweets.groupby(by = [\"DATE\"])\n",
    "sentiment = []\n",
    "date=[]\n",
    "for name,group in grouped_df:\n",
    "    date.append(name)\n",
    "    sentiment.append(group.sent.mean())\n",
    "stock_df = pd.DataFrame({\"Date\": date, \"Mean_Sentiment\": sentiment})\n",
    "\n",
    "# stock_df['Mean_Sentiment'] = stock_df['Mean_Sentiment'].apply(lambda x  : print(x) if x < 0 else x)\n",
    "stock_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date  increased  change_value  Mean_Sentiment\n",
      "0    2014-12-31          0     -0.610001        0.412905\n",
      "1    2015-01-05          0     -0.510000        1.224695\n",
      "2    2015-01-08          1      0.664999        0.594274\n",
      "3    2015-01-09          0     -0.164999        0.606336\n",
      "4    2015-01-14          1      0.190001        0.587961\n",
      "..          ...        ...           ...             ...\n",
      "985  2019-09-16          1      0.542499        0.470423\n",
      "986  2019-09-17          1      0.184997        0.465139\n",
      "987  2019-09-18          1      0.427502        0.439712\n",
      "988  2019-09-19          0     -0.262497        0.345741\n",
      "989  2019-09-20          0     -0.912502        0.418222\n",
      "\n",
      "[990 rows x 4 columns]\n",
      "                increased  change_value  Mean_Sentiment\n",
      "increased        1.000000      0.718894        0.028701\n",
      "change_value     0.718894      1.000000        0.053212\n",
      "Mean_Sentiment   0.028701      0.053212        1.000000\n"
     ]
    }
   ],
   "source": [
    "stock_data[\"increased\"] = np.where(stock_data[\"Close\"]>stock_data[\"Open\"], 1, 0)\n",
    "stock_data[\"change_value\"] = stock_data[\"Close\"]-stock_data[\"Open\"]\n",
    "# stock_data['Date'] = stock_data['date']\n",
    "\n",
    "# print(stock_data)\n",
    "# print(stock_df)\n",
    "\n",
    "x = pd.merge(stock_data, stock_df, on=\"Date\")\n",
    "# print(x)\n",
    "# x['Mean_Sentiment'] = x.Mean_Sentiment.shift(-1, fill_value=0)\n",
    "# x = x[x.apply(lambda x : int(x['Date'][:4]) > 2017, axis=1)]\n",
    "x = x.drop(columns=['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'])\n",
    "print(x)\n",
    "print(x.corr())\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# print(x[\"change_value\"].corr(x[\"Mean_Sentiment\"]))\n",
    "# print(x[\"increased\"].corr(x[\"Mean_Sentiment\"]))\n",
    "# print(pearsonr(x[\"change_value\"],x[\"Mean_Sentiment\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
